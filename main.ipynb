{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10a70261",
   "metadata": {},
   "source": [
    "# Ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54b1ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt\n",
    "\n",
    "# import capymoa\n",
    "# print(capymoa.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79567e1d",
   "metadata": {},
   "source": [
    "# Base de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10204aca",
   "metadata": {},
   "source": [
    "## CICDDoS2019"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd01e6d",
   "metadata": {},
   "source": [
    "### Downsample [Personalizado] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3552fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "DATASET_PATH = 'datasets/CICDDoS2019/'\n",
    "PANDAS_CHUNK_SIZE = 100000 \n",
    "ATTACK_LABEL_COL = ' Label' \n",
    "COLUMNS_TO_DROP = ['Unnamed: 0', 'Flow ID', 'SimillarHTTP']\n",
    "MIN_SAMPLES_PER_CHUNK = 1000\n",
    "BENIGN_LABEL = 'BENIGN'\n",
    "DOWNSAMPLE_FACTORS = {\n",
    "    'TFTP': 0.001,  # Redução mais agressiva \n",
    "    'MSSQL': 0.001,\n",
    "    'Default': 0.01  \n",
    "}\n",
    "\n",
    "ATTACK_ORDER = {\n",
    "    '03-11': [\n",
    "        'Portmap.csv', 'NetBIOS.csv', 'LDAP.csv', 'MSSQL.csv', 'UDP.csv', 'UDPLag.csv', 'Syn.csv'\n",
    "    ],\n",
    "    '01-12': [\n",
    "        'DrDoS_NTP.csv', 'DrDoS_DNS.csv', 'DrDoS_LDAP.csv', 'DrDoS_MSSQL.csv', 'DrDoS_NetBIOS.csv', 'DrDoS_SNMP.csv', 'DrDoS_SSDP.csv', 'DrDoS_UDP.csv', \n",
    "        'UDPLag.csv', 'Syn.csv', 'TFTP.csv' \n",
    "    ]\n",
    "}\n",
    "\n",
    "OUTPUT_FILES = {\n",
    "    '03-11': 'CICDDoS2019_03_11_Test.csv',\n",
    "    '01-12': 'CICDDoS2019_01_12_Train.csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a541a5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processar_e_salvar_dia(dia, dataset_path, chunk_size, cols_to_drop, attack_order, output_files):\n",
    "    \n",
    "    lista_arquivos = attack_order[dia]\n",
    "    output_filepath = output_files[dia]\n",
    "    total_amostras_mantidas = 0\n",
    "    header_escrito = False\n",
    "\n",
    "    with open(output_filepath, 'w', newline='', encoding='utf-8') as f:\n",
    "        \n",
    "        for filename in lista_arquivos:\n",
    "            filepath = os.path.join(dataset_path, dia, filename)\n",
    "            attack_name_from_file = filename.replace('.csv', '')\n",
    "            \n",
    "            try:\n",
    "                csv_reader = pd.read_csv(\n",
    "                    filepath, \n",
    "                    chunksize=chunk_size, \n",
    "                    low_memory=False, \n",
    "                    on_bad_lines='skip'\n",
    "                )\n",
    "            except Exception:\n",
    "                continue\n",
    "                \n",
    "            for df_chunk in csv_reader:\n",
    "                \n",
    "                # Limpeza de Colunas\n",
    "                cols_existentes_drop = [col for col in cols_to_drop if col in df_chunk.columns]\n",
    "                df_chunk = df_chunk.drop(columns=cols_existentes_drop, errors='ignore')\n",
    "                \n",
    "                # Normalização do Rótulo\n",
    "                df_chunk[ATTACK_LABEL_COL] = df_chunk[ATTACK_LABEL_COL].apply(\n",
    "                    lambda x: BENIGN_LABEL if 'BENIGN' in str(x).upper() else attack_name_from_file\n",
    "                )\n",
    "                \n",
    "                df_benign = df_chunk[df_chunk[ATTACK_LABEL_COL] == BENIGN_LABEL]\n",
    "                df_ataque = df_chunk[df_chunk[ATTACK_LABEL_COL] != BENIGN_LABEL]\n",
    "\n",
    "                # 3. Downsampling Seletivo nos Ataques\n",
    "                df_ataque_downsampled = df_ataque\n",
    "\n",
    "                if not df_ataque.empty:\n",
    "                    # Fator de Downsample específico\n",
    "                    factor = DOWNSAMPLE_FACTORS.get(attack_name_from_file, DOWNSAMPLE_FACTORS['Default'])\n",
    "                    \n",
    "                    # Se o número de amostras for MENOR que o mínimo, não fazemos Downsample (mantemos 100%)\n",
    "                    if len(df_ataque) < MIN_SAMPLES_PER_CHUNK:\n",
    "                        factor = 1.0\n",
    "                    \n",
    "                    if factor < 1.0:\n",
    "                        df_ataque_downsampled = df_ataque.sample(\n",
    "                            frac=factor, \n",
    "                            random_state=42\n",
    "                        )\n",
    "                    # Senão, df_ataque_downsampled permanece df_ataque (100% mantido)\n",
    "\n",
    "                # Combina (BENIGN 100% + Ataque Reduzido) e Embaralha\n",
    "                df_chunk_reduzido = pd.concat([df_benign, df_ataque_downsampled]).sample(frac=1, random_state=42)\n",
    "                \n",
    "                if df_chunk_reduzido.empty:\n",
    "                    continue\n",
    "\n",
    "                # Salvamento do Chunk Imediato\n",
    "                df_chunk_reduzido.to_csv(\n",
    "                    f, \n",
    "                    index=False, \n",
    "                    header=not header_escrito, \n",
    "                    mode='a' \n",
    "                )\n",
    "                header_escrito = True\n",
    "                total_amostras_mantidas += len(df_chunk_reduzido)\n",
    "\n",
    "    return total_amostras_mantidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f752cfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset de Teste salvo: CICDDoS2019_03_11_Test.csv (Total: 208,102 amostras)\n",
      "Dataset de Treino salvo: CICDDoS2019_01_12_Train.csv (Total: 376,216 amostras)\n"
     ]
    }
   ],
   "source": [
    "# tamanho_teste = processar_e_salvar_dia(\n",
    "#     dia='03-11', \n",
    "#     dataset_path=DATASET_PATH,\n",
    "#     chunk_size=PANDAS_CHUNK_SIZE,\n",
    "#     cols_to_drop=COLUMNS_TO_DROP,\n",
    "#     attack_order=ATTACK_ORDER,\n",
    "#     output_files=OUTPUT_FILES\n",
    "# )\n",
    "# print(f\"Dataset de Teste salvo: {OUTPUT_FILES['03-11']} (Total: {tamanho_teste:,} amostras)\")\n",
    "\n",
    "# tamanho_treino = processar_e_salvar_dia(\n",
    "#     dia='01-12', \n",
    "#     dataset_path=DATASET_PATH,\n",
    "#     chunk_size=PANDAS_CHUNK_SIZE,\n",
    "#     cols_to_drop=COLUMNS_TO_DROP,\n",
    "#     attack_order=ATTACK_ORDER,\n",
    "#     output_files=OUTPUT_FILES\n",
    "# )\n",
    "# print(f\"Dataset de Treino salvo: {OUTPUT_FILES['01-12']} (Total: {tamanho_treino:,} amostras)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f3cccd",
   "metadata": {},
   "source": [
    "### Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e8414d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from capymoa.stream import NumpyStream\n",
    "\n",
    "FILE_TRAIN = r'datasets\\CICDDoS2019\\CICDDoS2019_01_12_Train.csv'\n",
    "FILE_TEST = r'datasets\\CICDDoS2019\\CICDDoS2019_03_11_Test.csv'\n",
    "TARGET_LABEL = ' Label'\n",
    "TIMESTAMP_COLUMN = ' Timestamp'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d87f33",
   "metadata": {},
   "source": [
    "#### Funções de pré processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92993c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_stream_dataframe(df, target_label_col, timestamp_col, le_fit=None, is_train=False):\n",
    "    print(\"=\" * 60)\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    if timestamp_col in df_processed.columns:\n",
    "        print(f\"Convertendo coluna '{timestamp_col}' para datetime...\")\n",
    "        df_processed[timestamp_col] = pd.to_datetime(df_processed[timestamp_col], errors='coerce')\n",
    "    else:\n",
    "        print(f\"Aviso: Coluna de timestamp '{timestamp_col}' não encontrada.\")\n",
    "    \n",
    "    # Trata valores infinitos\n",
    "    df_processed.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    \n",
    "    # Remove colunas 'object' desnecessárias\n",
    "    cols_to_drop_objects = [col for col in df_processed.columns \n",
    "                            if df_processed[col].dtype == 'object' and col != target_label_col]\n",
    "    \n",
    "    if cols_to_drop_objects:\n",
    "        print(f\"Removendo colunas 'object': {cols_to_drop_objects}\")\n",
    "        df_processed.drop(columns=cols_to_drop_objects, errors='ignore', inplace=True)\n",
    "\n",
    "    le = le_fit\n",
    "    \n",
    "    if target_label_col in df_processed.columns:\n",
    "        if is_train:\n",
    "            print(\"Codificando rótulos (modo treino)...\")\n",
    "            le = LabelEncoder()\n",
    "            df_processed[target_label_col] = le.fit_transform(df_processed[target_label_col].astype(str))\n",
    "        elif le_fit is not None:\n",
    "            print(\"Codificando rótulos (modo teste/predição)...\")\n",
    "            \n",
    "            def transform_label(label):\n",
    "                try:\n",
    "                    # Tenta transformar rótulo conhecido\n",
    "                    return le.transform([label])[0]\n",
    "                except ValueError:\n",
    "                    # Atribui um novo índice para rótulo desconhecido\n",
    "                    return len(le.classes_) \n",
    "            \n",
    "            df_processed[target_label_col] = df_processed[target_label_col].astype(str).apply(transform_label)\n",
    "        else:\n",
    "            print(f\"Aviso: 'is_train=False' mas nenhum 'le_fit' foi fornecido. Rótulos não serão codificados.\")\n",
    "            \n",
    "    # Preenchimento de Nulos \n",
    "    print(\"Preenchendo valores ausentes (NaN/NaT) com 0...\")\n",
    "    df_processed.fillna(0, inplace=True)\n",
    "    \n",
    "    # Ordenação \n",
    "    if timestamp_col in df_processed.columns:\n",
    "        print(f\"Ordenando DataFrame por '{timestamp_col}'...\")\n",
    "        df_processed.sort_values(by=timestamp_col, inplace=True)\n",
    "        df_processed.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Mover Rótulo para o Final\n",
    "    if target_label_col in df_processed.columns:\n",
    "        print(f\"Movendo coluna alvo '{target_label_col}' para o final...\")\n",
    "        label_col_data = df_processed.pop(target_label_col)\n",
    "        df_processed[target_label_col] = label_col_data\n",
    "        \n",
    "    print(f\"Pré-processamento concluído. Shape final: {df_processed.shape}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return df_processed, le\n",
    "\n",
    "\n",
    "def analisar_qualidade_dados(df, nome_df):\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nValores Nulos (NaN) por Coluna:\")\n",
    "    nan_counts = df.isnull().sum()\n",
    "    nan_counts_filtered = nan_counts[nan_counts > 0].sort_values(ascending=False)\n",
    "    \n",
    "    if nan_counts_filtered.empty:\n",
    "        print(\"Nenhum valor nulo (NaN) encontrado.\")\n",
    "    else:\n",
    "        print(nan_counts_filtered)\n",
    "\n",
    "    # --- Contagem de Valores Infinitos (inf ou -inf) ---\n",
    "    df_numeric = df.select_dtypes(include=np.number)\n",
    "    \n",
    "    print(\"\\nValores Infinitos (inf/-inf) por Coluna:\")\n",
    "    if df_numeric.empty:\n",
    "        print(\"Nenhuma coluna numérica encontrada para checar infinitos.\")\n",
    "    else:\n",
    "        # np.isinf() aplicado ao DataFrame numérico e somado por coluna\n",
    "        is_inf = np.isinf(df_numeric).sum()\n",
    "        is_inf_filtered = is_inf[is_inf > 0].sort_values(ascending=False)\n",
    "        \n",
    "        if is_inf_filtered.empty:\n",
    "            print(\"Nenhum valor infinito (inf/-inf) encontrado.\")\n",
    "        else:\n",
    "            print(is_inf_filtered)\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "def criar_stream(df, target_label_col, timestamp_col, stream_name=\"\"):\n",
    "    print(f\"Iniciando criação do stream de dados: {stream_name}\")\n",
    "\n",
    "    cols_to_drop_from_X = [target_label_col, timestamp_col]\n",
    "    y_data = df[target_label_col].values\n",
    "    X_data = df.drop(columns=cols_to_drop_from_X).values \n",
    "    feature_names = list(df.drop(columns=cols_to_drop_from_X).columns)\n",
    "\n",
    "    # Criar o Stream\n",
    "    stream = NumpyStream(\n",
    "        X=X_data,\n",
    "        y=y_data,\n",
    "        feature_names=feature_names,\n",
    "        target_name=target_label_col\n",
    "    )\n",
    "    stream.restart()\n",
    "\n",
    "    return stream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464d9c0d",
   "metadata": {},
   "source": [
    "#### Análise dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fc34c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Treino ===\n",
      " Label\n",
      "BENIGN           56863\n",
      "DrDoS_SNMP       51606\n",
      "DrDoS_DNS        50715\n",
      "DrDoS_MSSQL      45229\n",
      "DrDoS_NetBIOS    40936\n",
      "DrDoS_UDP        31349\n",
      "DrDoS_SSDP       26109\n",
      "DrDoS_LDAP       21800\n",
      "TFTP             20087\n",
      "Syn              15824\n",
      "DrDoS_NTP        12029\n",
      "UDPLag            3669\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Teste ===\n",
      " Label\n",
      "BENIGN     56965\n",
      "Syn        42852\n",
      "UDP        37795\n",
      "NetBIOS    34549\n",
      "LDAP       21083\n",
      "UDPLag      7212\n",
      "MSSQL       5776\n",
      "Portmap     1870\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Treino\n",
    "print(\"=== Treino ===\")\n",
    "df_train = pd.read_csv(FILE_TRAIN)\n",
    "print(df_train.value_counts(' Label'))\n",
    "\n",
    "# Teste\n",
    "print(\"\\n=== Teste ===\")\n",
    "df_test = pd.read_csv(FILE_TEST)\n",
    "print(df_test.value_counts(' Label'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e57876",
   "metadata": {},
   "source": [
    "#### Verificação de valores Inf e Ausentes / Ordenação Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fc9facb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "\n",
      "Valores Nulos (NaN) por Coluna:\n",
      "Flow Bytes/s    2462\n",
      "dtype: int64\n",
      "\n",
      "Valores Infinitos (inf/-inf) por Coluna:\n",
      " Flow Packets/s    8882\n",
      "Flow Bytes/s       6420\n",
      "dtype: int64\n",
      "============================================================\n",
      "============================================================\n",
      "Convertendo coluna ' Timestamp' para datetime...\n",
      "Removendo colunas 'object': [' Source IP', ' Destination IP']\n",
      "Codificando rótulos (modo treino)...\n",
      "Preenchendo valores ausentes (NaN/NaT) com 0...\n",
      "Ordenando DataFrame por ' Timestamp'...\n",
      "Movendo coluna alvo ' Label' para o final...\n",
      "Pré-processamento concluído. Shape final: (376216, 83)\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "Valores Nulos (NaN) por Coluna:\n",
      "Nenhum valor nulo (NaN) encontrado.\n",
      "\n",
      "Valores Infinitos (inf/-inf) por Coluna:\n",
      "Nenhum valor infinito (inf/-inf) encontrado.\n",
      "============================================================\n",
      "Train ordenado por Timestamp: True\n"
     ]
    }
   ],
   "source": [
    "analisar_qualidade_dados(df_train, \"df_train (ANTES da Limpeza)\")\n",
    "\n",
    "# Limpa os dados de treino e \"treina\" o codificador de rótulos\n",
    "df_train_cleaned, le_trained = preprocess_stream_dataframe(\n",
    "    df=df_train,\n",
    "    target_label_col=TARGET_LABEL,\n",
    "    timestamp_col=TIMESTAMP_COLUMN,\n",
    "    is_train=True\n",
    ")\n",
    "\n",
    "analisar_qualidade_dados(df_train_cleaned, \"df_train_cleaned (APÓS a Limpeza)\")\n",
    "is_sorted_train = df_train_cleaned[TIMESTAMP_COLUMN].is_monotonic_increasing\n",
    "print(f\"Train ordenado por Timestamp: {is_sorted_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cbdffbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "\n",
      "Valores Nulos (NaN) por Coluna:\n",
      "Flow Bytes/s    46\n",
      "dtype: int64\n",
      "\n",
      "Valores Infinitos (inf/-inf) por Coluna:\n",
      " Flow Packets/s    7005\n",
      "Flow Bytes/s       6959\n",
      "dtype: int64\n",
      "============================================================\n",
      "============================================================\n",
      "Convertendo coluna ' Timestamp' para datetime...\n",
      "Removendo colunas 'object': [' Source IP', ' Destination IP']\n",
      "Codificando rótulos (modo teste/predição)...\n",
      "Preenchendo valores ausentes (NaN/NaT) com 0...\n",
      "Ordenando DataFrame por ' Timestamp'...\n",
      "Movendo coluna alvo ' Label' para o final...\n",
      "Pré-processamento concluído. Shape final: (208102, 83)\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "Valores Nulos (NaN) por Coluna:\n",
      "Nenhum valor nulo (NaN) encontrado.\n",
      "\n",
      "Valores Infinitos (inf/-inf) por Coluna:\n",
      "Nenhum valor infinito (inf/-inf) encontrado.\n",
      "============================================================\n",
      "Test ordenado por Timestamp: True\n"
     ]
    }
   ],
   "source": [
    "analisar_qualidade_dados(df_test, \"df_test (ANTES da Limpeza)\")\n",
    "\n",
    "df_test_cleaned, _ = preprocess_stream_dataframe(\n",
    "    df=df_test,\n",
    "    target_label_col=TARGET_LABEL,\n",
    "    timestamp_col=TIMESTAMP_COLUMN,\n",
    "    le_fit=le_trained,\n",
    "    is_train=False\n",
    ")\n",
    "\n",
    "analisar_qualidade_dados(df_test_cleaned, \"df_test_cleaned (APÓS a Limpeza)\")\n",
    "is_sorted_test = df_test_cleaned[TIMESTAMP_COLUMN].is_monotonic_increasing\n",
    "print(f\"Test ordenado por Timestamp: {is_sorted_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82bc7fe",
   "metadata": {},
   "source": [
    "## CICIDS2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b4a340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Label\n",
      "BENIGN              440031\n",
      "DoS Hulk            231073\n",
      "DoS GoldenEye        10293\n",
      "DoS slowloris         5796\n",
      "DoS Slowhttptest      5499\n",
      "Heartbleed              11\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>...</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>38308</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>389</td>\n",
       "      <td>479</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>326</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>15.636364</td>\n",
       "      <td>31.449238</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88</td>\n",
       "      <td>1095</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>3150</td>\n",
       "      <td>3150</td>\n",
       "      <td>1575</td>\n",
       "      <td>0</td>\n",
       "      <td>315.000000</td>\n",
       "      <td>632.561635</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>389</td>\n",
       "      <td>15206</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>3452</td>\n",
       "      <td>6660</td>\n",
       "      <td>1313</td>\n",
       "      <td>0</td>\n",
       "      <td>203.058823</td>\n",
       "      <td>425.778474</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88</td>\n",
       "      <td>1092</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>3150</td>\n",
       "      <td>3152</td>\n",
       "      <td>1575</td>\n",
       "      <td>0</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>694.509719</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Destination Port   Flow Duration   Total Fwd Packets  \\\n",
       "0                 80           38308                   1   \n",
       "1                389             479                  11   \n",
       "2                 88            1095                  10   \n",
       "3                389           15206                  17   \n",
       "4                 88            1092                   9   \n",
       "\n",
       "    Total Backward Packets  Total Length of Fwd Packets  \\\n",
       "0                        1                            6   \n",
       "1                        5                          172   \n",
       "2                        6                         3150   \n",
       "3                       12                         3452   \n",
       "4                        6                         3150   \n",
       "\n",
       "    Total Length of Bwd Packets   Fwd Packet Length Max  \\\n",
       "0                             6                       6   \n",
       "1                           326                      79   \n",
       "2                          3150                    1575   \n",
       "3                          6660                    1313   \n",
       "4                          3152                    1575   \n",
       "\n",
       "    Fwd Packet Length Min   Fwd Packet Length Mean   Fwd Packet Length Std  \\\n",
       "0                       6                 6.000000                0.000000   \n",
       "1                       0                15.636364               31.449238   \n",
       "2                       0               315.000000              632.561635   \n",
       "3                       0               203.058823              425.778474   \n",
       "4                       0               350.000000              694.509719   \n",
       "\n",
       "   ...   min_seg_size_forward  Active Mean   Active Std   Active Max  \\\n",
       "0  ...                     20          0.0          0.0            0   \n",
       "1  ...                     32          0.0          0.0            0   \n",
       "2  ...                     32          0.0          0.0            0   \n",
       "3  ...                     32          0.0          0.0            0   \n",
       "4  ...                     32          0.0          0.0            0   \n",
       "\n",
       "    Active Min  Idle Mean   Idle Std   Idle Max   Idle Min   Label  \n",
       "0            0        0.0        0.0          0          0  BENIGN  \n",
       "1            0        0.0        0.0          0          0  BENIGN  \n",
       "2            0        0.0        0.0          0          0  BENIGN  \n",
       "3            0        0.0        0.0          0          0  BENIGN  \n",
       "4            0        0.0        0.0          0          0  BENIGN  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('datasets\\CIC-IDS-2017\\Wednesday-workingHours.pcap_ISCX.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0a357fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Label\n",
      "BENIGN              440031\n",
      "DoS Hulk            231073\n",
      "DoS GoldenEye        10293\n",
      "DoS slowloris         5796\n",
      "DoS Slowhttptest      5499\n",
      "Heartbleed              11\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.value_counts(' Label'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d942251e",
   "metadata": {},
   "source": [
    "# Algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfbe6dd",
   "metadata": {},
   "source": [
    "## LeveragingBagging\n",
    "\n",
    "https://capymoa.org/api/modules/capymoa.classifier.LeveragingBagging.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8bd386d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from capymoa.classifier import LeveragingBagging\n",
    "from capymoa.evaluation import prequential_evaluation\n",
    "from capymoa.stream import stream_from_file\n",
    "from capymoa.evaluation import ClassificationEvaluator\n",
    "import math\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6639c5d",
   "metadata": {},
   "source": [
    "### Criação dos dados stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2d80c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando criação do stream de dados: Treino\n",
      "\n",
      "Iniciando criação do stream de dados: Teste\n"
     ]
    }
   ],
   "source": [
    "# Chamar a função para criar o stream \n",
    "train_stream = criar_stream(\n",
    "    df=df_train_cleaned,\n",
    "    target_label_col=TARGET_LABEL,\n",
    "    timestamp_col=TIMESTAMP_COLUMN,\n",
    "    stream_name=\"Treino\"\n",
    ")\n",
    "\n",
    "test_stream = criar_stream(\n",
    "    df=df_test_cleaned,\n",
    "    target_label_col=TARGET_LABEL,\n",
    "    timestamp_col=TIMESTAMP_COLUMN,\n",
    "    stream_name=\"Teste\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0797807",
   "metadata": {},
   "source": [
    "### Treinamento e Testando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bce02758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando Treinamento...\n",
      "\n",
      "Resultados de Avaliação (Treino):\n",
      "Acurácia Cumulativa: 99.0519\n",
      "F1-Score Cumulativo: 98.3268\n",
      "Tempo de Treinamento: 314.32 segundos\n"
     ]
    }
   ],
   "source": [
    "# Inicializa o classificador com o esquema do stream\n",
    "classifier = LeveragingBagging(schema=train_stream.get_schema())\n",
    "\n",
    "# AVALIAÇÃO NO CONJUNTO DE TREINO\n",
    "print(\"Iniciando Treinamento...\")\n",
    "start_train_time = time.time()\n",
    "\n",
    "results_train = prequential_evaluation(\n",
    "    stream=train_stream,\n",
    "    learner=classifier,\n",
    "    batch_size=1\n",
    ")\n",
    "\n",
    "end_train_time = time.time() \n",
    "training_duration = end_train_time - start_train_time\n",
    "\n",
    "print(\"\\nResultados de Avaliação (Treino):\")\n",
    "print(f\"Acurácia Cumulativa: {results_train['cumulative'].accuracy():.4f}\")\n",
    "print(f\"F1-Score Cumulativo: {results_train['cumulative'].f1_score():.4f}\")\n",
    "print(f\"Tempo de Treinamento: {training_duration:.2f} segundos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a2fa72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando Teste...\n",
      "\n",
      "Resultados de Avaliação (Teste):\n",
      "Acurácia Cumulativa: 27.3736\n",
      "F1-Score Cumulativo: nan\n",
      "Tempo de Teste: 57.44 segundos\n"
     ]
    }
   ],
   "source": [
    "# AVALIAÇÃO NO CONJUNTO DE TESTE\n",
    "print(\"\\nIniciando Teste...\")\n",
    "test_stream.restart() # Resetar o stream de teste para o início \n",
    "\n",
    "# Criar um novo objeto avaliador para o teste\n",
    "test_evaluator = ClassificationEvaluator(schema=test_stream.get_schema())\n",
    "\n",
    "# Loop manual de TESTE \n",
    "start_test_time = time.time()\n",
    "while test_stream.has_more_instances():\n",
    "    instance = test_stream.next_instance()\n",
    "    prediction = classifier.predict(instance)\n",
    "    test_evaluator.update(instance.y_index, prediction)\n",
    "\n",
    "end_test_time = time.time() \n",
    "test_duration = end_test_time - start_test_time\n",
    "\n",
    "print(\"\\nResultados de Avaliação (Teste):\")\n",
    "print(f\"Acurácia Cumulativa: {test_evaluator.accuracy():.4f}\")\n",
    "print(f\"F1-Score Cumulativo: {test_evaluator.f1_score():.4f}\")\n",
    "print(f\"Tempo de Teste: {test_duration:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56360b06",
   "metadata": {},
   "source": [
    "## HoeffdingAdaptiveTree\n",
    "\n",
    "https://capymoa.org/api/modules/capymoa.classifier.HoeffdingAdaptiveTree.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16646744",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
